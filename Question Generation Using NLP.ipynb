{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe81b6b6510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import CRFTagger\n",
    "import pycrfsuite\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "#Import PyTorch Framework\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ct = CRFTagger()\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the train set data\n",
    "#train_set  = pd.read_csv('Train_and_test_data/train.txt',sep=' ',names=['word','Brill','tag']).drop('Brill',1)\n",
    "# Format train set data to tuples of a list of lists\n",
    "#train_set = [[tuple(x) for x in train_set.values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time there was a wicked sprite, indeed he was the most mischievous of all sprites. One day he was in a very good humor, for he had made a mirror with the power of causing all that was good and beautiful when it was reflected therein, to look poor and mean; but that which was good-for-nothing and looked ugly was shown magnified and increased in ugliness. In this mirror the most beautiful landscapes looked like boiled spinach, and the best persons were turned into frights, or appeared to stand on their heads; their faces were so distorted that they were not to be recognised; and if anyone had a mole, you might be sure that it would be magnified and spread over both nose and mouth.\\n \\n \"That\\'s glorious fun!\" said the sprite. If a good thought passed through a man\\'s mind, then a grin was seen in the mirror, and the sprite laughed heartily at his clever discovery. All the little sprites who went to his school--for he kept a sprite school--told each other that a miracle had happened; and that now only, as they thought, it would be possible to see how the world really looked. They ran about with the mirror; and at last there was not a land or a person who was not represented distorted in the mirror. So then they thought they would fly up to the sky, and have a joke there. The higher they flew with the mirror, the more terribly it grinned: they could hardly hold it fast. Higher and higher still they flew, nearer and nearer to the stars, when suddenly the mirror shook so terribly with grinning, that it flew out of their hands and fell to the earth, where it was dashed in a hundred million and more pieces. And now it worked much more evil than before; for some of these pieces were hardly so large as a grain of sand, and they flew about in the wide world, and when they got into people\\'s eyes, there they stayed; and then people saw everything perverted, or only had an eye for that which was evil. This happened because the very smallest bit had the same power which the whole mirror had possessed. Some persons even got a splinter in their heart, and then it made one shudder, for their heart became like a lump of ice. Some of the broken pieces were so large that they were used for windowpanes, through which one could not see one\\'s friends. Other pieces were put in spectacles; and that was a sad affair when people put on their glasses to see well and rightly. Then the wicked sprite laughed till he almost choked, for all this tickled his fancy. The fine splinters still flew about in the air: and now we shall hear what happened next.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Code, Keep it commented unless retraining\n",
    "#ct.train(train_set,'model.crf.tagger') \n",
    "\n",
    "#sentence = \"Once upon a time there was a little girl called Cinderella. Cinderella is met a fairy who grants her a wish to be a Princess. Fairy said to Cinderella that she will become a Princess for one night\"\n",
    "#sentence = \"Once upon a time there was a little girl called Alice . One day Alice met a Rabbit . The Rabbit said to Alice , follow me Alice I will carry you to my Den\"\n",
    "\n",
    "# Read the Test data from txt\n",
    "sentence = ' '.join(open('Text_Passages1.txt','r').readlines()).rstrip(\"\\n\")\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_text(passage):\n",
    "    \"\"\"\n",
    "    1.Remove Punctuations and Special characters appear in book chapters\n",
    "    2.Remove Stopwords\n",
    "    3.Return Clean list of words\n",
    "    \"\"\"\n",
    "    exclude_set = set(['“','”',':'])\n",
    "\n",
    "    no_punctuation = [char for char in passage if char not in string.punctuation + \"“”.\"]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    no_punctuation = [word for word in no_punctuation.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upon time wicked sprite indeed mischievous sprites One day good humor made mirror power causing good beautiful reflected therein look poor mean goodfornothing looked ugly shown magnified increased ugliness mirror beautiful landscapes looked like boiled spinach best persons turned frights appeared stand heads faces distorted recognised anyone mole might sure would magnified spread nose mouth Thats glorious fun said sprite good thought passed mans mind grin seen mirror sprite laughed heartily clever discovery little sprites went schoolfor kept sprite schooltold miracle happened thought would possible see world really looked ran mirror last land person represented distorted mirror thought would fly sky joke higher flew mirror terribly grinned could hardly hold fast Higher higher still flew nearer nearer stars suddenly mirror shook terribly grinning flew hands fell earth dashed hundred million pieces worked much evil pieces hardly large grain sand flew wide world got peoples eyes stayed people saw everything perverted eye evil happened smallest bit power whole mirror possessed persons even got splinter heart made one shudder heart became like lump ice broken pieces large used windowpanes one could see ones friends pieces put spectacles sad affair people put glasses see well rightly wicked sprite laughed till almost choked tickled fancy fine splinters still flew air shall hear happened next\n"
     ]
    }
   ],
   "source": [
    "#remove stop words and punctuation\n",
    "sentence = process_text(sentence)\n",
    "sentence = ' '.join(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(sentence)\n",
    "word_list = [[]]\n",
    "word_list.clear()\n",
    "wlist = []\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for sent in sentences:\n",
    "    for word in sent.split():\n",
    "        wlist.append(word)\n",
    "        j += 1\n",
    "        \n",
    "    wlist.copy\n",
    "    word_list.append(wlist.copy())\n",
    "    wlist.clear()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Set the model of previously trained data set\n",
    "ct.set_model_file(model_file='model.crf.tagger')\n",
    "word_list = ct.tag_sents(word_list)\n",
    "\n",
    "#test_set = pd.read_csv('Train_and_test_data/test.txt', sep=' ', names=['words','Brill','tag'], index_col=False).drop(['Brill','tag'],1)\n",
    "#test_set = test_set.values.tolist()\n",
    "#ct.tag_sents(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_setEval = pd.read_csv('Train_and_test_data/test.txt', sep=' ', names=['words','Brill','tag']).drop('Brill',1)\n",
    "#test_setEval = [[tuple(x) for x in test_setEval.values]]\n",
    "#test the accuracy of the POS\n",
    "#ct.evaluate(test_setEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['upon', 'B-PP'],\n",
       "       ['time', 'B-NP'],\n",
       "       ['wicked', 'B-VP'],\n",
       "       ['sprite', 'I-VP'],\n",
       "       ['indeed', 'I-VP'],\n",
       "       ['mischievous', 'B-NP'],\n",
       "       ['sprites', 'I-NP'],\n",
       "       ['One', 'I-NP'],\n",
       "       ['day', 'I-NP'],\n",
       "       ['good', 'I-NP'],\n",
       "       ['humor', 'I-NP'],\n",
       "       ['made', 'B-VP'],\n",
       "       ['mirror', 'B-NP'],\n",
       "       ['power', 'I-NP'],\n",
       "       ['causing', 'B-VP'],\n",
       "       ['good', 'B-ADJP'],\n",
       "       ['beautiful', 'I-ADJP'],\n",
       "       ['reflected', 'B-VP'],\n",
       "       ['therein', 'I-VP'],\n",
       "       ['look', 'I-VP'],\n",
       "       ['poor', 'I-VP'],\n",
       "       ['mean', 'I-VP'],\n",
       "       ['goodfornothing', 'I-VP'],\n",
       "       ['looked', 'I-VP'],\n",
       "       ['ugly', 'I-VP'],\n",
       "       ['shown', 'I-VP'],\n",
       "       ['magnified', 'I-VP'],\n",
       "       ['increased', 'B-NP'],\n",
       "       ['ugliness', 'I-NP'],\n",
       "       ['mirror', 'I-NP'],\n",
       "       ['beautiful', 'I-NP'],\n",
       "       ['landscapes', 'I-NP'],\n",
       "       ['looked', 'B-VP'],\n",
       "       ['like', 'I-VP'],\n",
       "       ['boiled', 'I-VP'],\n",
       "       ['spinach', 'B-NP'],\n",
       "       ['best', 'I-NP'],\n",
       "       ['persons', 'I-NP'],\n",
       "       ['turned', 'B-VP'],\n",
       "       ['frights', 'B-NP'],\n",
       "       ['appeared', 'B-VP'],\n",
       "       ['stand', 'I-VP'],\n",
       "       ['heads', 'B-NP'],\n",
       "       ['faces', 'B-VP'],\n",
       "       ['distorted', 'I-VP'],\n",
       "       ['recognised', 'I-VP'],\n",
       "       ['anyone', 'B-NP'],\n",
       "       ['mole', 'I-NP'],\n",
       "       ['might', 'B-VP'],\n",
       "       ['sure', 'B-ADJP'],\n",
       "       ['would', 'B-VP'],\n",
       "       ['magnified', 'I-VP'],\n",
       "       ['spread', 'I-VP'],\n",
       "       ['nose', 'I-VP'],\n",
       "       ['mouth', 'B-NP'],\n",
       "       ['Thats', 'I-NP'],\n",
       "       ['glorious', 'I-NP'],\n",
       "       ['fun', 'I-NP'],\n",
       "       ['said', 'B-VP'],\n",
       "       ['sprite', 'I-VP'],\n",
       "       ['good', 'B-ADJP'],\n",
       "       ['thought', 'B-VP'],\n",
       "       ['passed', 'I-VP'],\n",
       "       ['mans', 'B-NP'],\n",
       "       ['mind', 'B-VP'],\n",
       "       ['grin', 'I-VP'],\n",
       "       ['seen', 'I-VP'],\n",
       "       ['mirror', 'I-VP'],\n",
       "       ['sprite', 'I-VP'],\n",
       "       ['laughed', 'I-VP'],\n",
       "       ['heartily', 'B-NP'],\n",
       "       ['clever', 'I-NP'],\n",
       "       ['discovery', 'I-NP'],\n",
       "       ['little', 'I-NP'],\n",
       "       ['sprites', 'I-NP'],\n",
       "       ['went', 'B-VP'],\n",
       "       ['schoolfor', 'I-VP'],\n",
       "       ['kept', 'I-VP'],\n",
       "       ['sprite', 'I-VP'],\n",
       "       ['schooltold', 'I-VP'],\n",
       "       ['miracle', 'I-VP'],\n",
       "       ['happened', 'I-VP'],\n",
       "       ['thought', 'B-NP'],\n",
       "       ['would', 'B-VP'],\n",
       "       ['possible', 'B-ADJP'],\n",
       "       ['see', 'B-VP'],\n",
       "       ['world', 'I-VP'],\n",
       "       ['really', 'I-VP'],\n",
       "       ['looked', 'I-VP'],\n",
       "       ['ran', 'I-VP'],\n",
       "       ['mirror', 'I-VP'],\n",
       "       ['last', 'B-NP'],\n",
       "       ['land', 'I-NP'],\n",
       "       ['person', 'I-NP'],\n",
       "       ['represented', 'B-VP'],\n",
       "       ['distorted', 'I-VP'],\n",
       "       ['mirror', 'I-VP'],\n",
       "       ['thought', 'B-NP'],\n",
       "       ['would', 'B-VP'],\n",
       "       ['fly', 'B-ADJP'],\n",
       "       ['sky', 'I-ADJP'],\n",
       "       ['joke', 'I-ADJP'],\n",
       "       ['higher', 'I-ADJP'],\n",
       "       ['flew', 'I-ADJP'],\n",
       "       ['mirror', 'I-ADJP'],\n",
       "       ['terribly', 'I-ADJP'],\n",
       "       ['grinned', 'I-ADJP'],\n",
       "       ['could', 'B-VP'],\n",
       "       ['hardly', 'I-VP'],\n",
       "       ['hold', 'I-VP'],\n",
       "       ['fast', 'I-VP'],\n",
       "       ['Higher', 'B-NP'],\n",
       "       ['higher', 'I-NP'],\n",
       "       ['still', 'B-ADVP'],\n",
       "       ['flew', 'B-VP'],\n",
       "       ['nearer', 'B-NP'],\n",
       "       ['nearer', 'I-NP'],\n",
       "       ['stars', 'B-VP'],\n",
       "       ['suddenly', 'I-VP'],\n",
       "       ['mirror', 'I-VP'],\n",
       "       ['shook', 'I-VP'],\n",
       "       ['terribly', 'I-VP'],\n",
       "       ['grinning', 'I-VP'],\n",
       "       ['flew', 'B-NP'],\n",
       "       ['hands', 'I-NP'],\n",
       "       ['fell', 'B-VP'],\n",
       "       ['earth', 'B-ADJP'],\n",
       "       ['dashed', 'B-VP'],\n",
       "       ['hundred', 'I-VP'],\n",
       "       ['million', 'B-NP'],\n",
       "       ['pieces', 'I-NP'],\n",
       "       ['worked', 'B-VP'],\n",
       "       ['much', 'B-NP'],\n",
       "       ['evil', 'I-NP'],\n",
       "       ['pieces', 'I-NP'],\n",
       "       ['hardly', 'I-NP'],\n",
       "       ['large', 'I-NP'],\n",
       "       ['grain', 'I-NP'],\n",
       "       ['sand', 'I-NP'],\n",
       "       ['flew', 'I-NP'],\n",
       "       ['wide', 'I-NP'],\n",
       "       ['world', 'I-NP'],\n",
       "       ['got', 'I-NP'],\n",
       "       ['peoples', 'I-NP'],\n",
       "       ['eyes', 'I-NP'],\n",
       "       ['stayed', 'B-VP'],\n",
       "       ['people', 'B-NP'],\n",
       "       ['saw', 'B-VP'],\n",
       "       ['everything', 'I-VP'],\n",
       "       ['perverted', 'I-VP'],\n",
       "       ['eye', 'I-VP'],\n",
       "       ['evil', 'I-VP'],\n",
       "       ['happened', 'I-VP'],\n",
       "       ['smallest', 'B-NP'],\n",
       "       ['bit', 'I-NP'],\n",
       "       ['power', 'I-NP'],\n",
       "       ['whole', 'I-NP'],\n",
       "       ['mirror', 'I-NP'],\n",
       "       ['possessed', 'B-VP'],\n",
       "       ['persons', 'B-NP'],\n",
       "       ['even', 'I-NP'],\n",
       "       ['got', 'I-NP'],\n",
       "       ['splinter', 'I-NP'],\n",
       "       ['heart', 'I-NP'],\n",
       "       ['made', 'B-VP'],\n",
       "       ['one', 'B-NP'],\n",
       "       ['shudder', 'I-NP'],\n",
       "       ['heart', 'I-NP'],\n",
       "       ['became', 'B-VP'],\n",
       "       ['like', 'I-VP'],\n",
       "       ['lump', 'I-VP'],\n",
       "       ['ice', 'I-VP'],\n",
       "       ['broken', 'I-VP'],\n",
       "       ['pieces', 'B-NP'],\n",
       "       ['large', 'I-NP'],\n",
       "       ['used', 'B-VP'],\n",
       "       ['windowpanes', 'B-NP'],\n",
       "       ['one', 'I-NP'],\n",
       "       ['could', 'B-VP'],\n",
       "       ['see', 'I-VP'],\n",
       "       ['ones', 'B-NP'],\n",
       "       ['friends', 'I-NP'],\n",
       "       ['pieces', 'I-NP'],\n",
       "       ['put', 'I-NP'],\n",
       "       ['spectacles', 'I-NP'],\n",
       "       ['sad', 'I-NP'],\n",
       "       ['affair', 'I-NP'],\n",
       "       ['people', 'I-NP'],\n",
       "       ['put', 'I-NP'],\n",
       "       ['glasses', 'B-VP'],\n",
       "       ['see', 'I-VP'],\n",
       "       ['well', 'I-VP'],\n",
       "       ['rightly', 'I-VP'],\n",
       "       ['wicked', 'I-VP'],\n",
       "       ['sprite', 'I-VP'],\n",
       "       ['laughed', 'I-VP'],\n",
       "       ['till', 'I-VP'],\n",
       "       ['almost', 'I-VP'],\n",
       "       ['choked', 'I-VP'],\n",
       "       ['tickled', 'I-VP'],\n",
       "       ['fancy', 'B-NP'],\n",
       "       ['fine', 'I-NP'],\n",
       "       ['splinters', 'I-NP'],\n",
       "       ['still', 'B-ADVP'],\n",
       "       ['flew', 'B-VP'],\n",
       "       ['air', 'I-VP'],\n",
       "       ['shall', 'I-VP'],\n",
       "       ['hear', 'I-VP'],\n",
       "       ['happened', 'I-VP'],\n",
       "       ['next', 'I-VP']], \n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert list of tuples to a numpy array\n",
    "word_list = np.array(word_list)\n",
    "word_list = np.reshape(word_list, (-1,2))\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find S -> NP VP NP\n",
    "# Returns if a subject is found\n",
    "# pattern variable = [pat0, pat1, pat2]\n",
    "def findSubject(pattern):\n",
    "    #print('{} -> {} {}'.format(pattern[0], pattern[1], pattern[2]))\n",
    "    if pattern[0] == 'NP' and pattern[1] == 'VP' and pattern[2] == 'NP':\n",
    "        #if true pattern[0] is the subject of a sentence\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Subject Found at index 10\n",
      "Subject -> humor => made mirror\n",
      "--------------------\n",
      "Potential Subject Found at index 37\n",
      "Subject -> persons => turned frights\n",
      "--------------------\n",
      "Potential Subject Found at index 130\n",
      "Subject -> pieces => worked much\n",
      "--------------------\n",
      "Potential Subject Found at index 144\n",
      "Subject -> eyes => stayed people\n",
      "--------------------\n",
      "Potential Subject Found at index 157\n",
      "Subject -> mirror => possessed persons\n",
      "--------------------\n",
      "Potential Subject Found at index 163\n",
      "Subject -> heart => made one\n",
      "--------------------\n",
      "Potential Subject Found at index 174\n",
      "Subject -> large => used windowpanes\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#Extract the Subject -> NP VP NP to find the subjects in a sentence\n",
    "#using Markov Chain Model\n",
    "\n",
    "pattern = []\n",
    "subjects = []\n",
    "word_list_length = len(word_list)\n",
    "\n",
    "for i in range(0, len(word_list)):\n",
    "    #print(word_list[i][1].split('-')[1])\n",
    "    try:\n",
    "        if((word_list_length - i == 2)):\n",
    "            break\n",
    "        else:\n",
    "            pattern = [word_list[i][1].split('-')[1], word_list[i+1][1].split('-')[1], word_list[i+2][1].split('-')[1]]\n",
    "            # Call the function findSubject to identify potential subject elements and save them in an array\n",
    "            if findSubject(pattern):\n",
    "                # If returns true consider 1st element as a potential Subject\n",
    "                print('Potential Subject Found at index {}'.format(i))\n",
    "                print('Subject -> {} => {} {}'.format(word_list[i][0], word_list[i+1][0], word_list[i+2][0]))\n",
    "                # Put the phrases in to a sentece and append it to an array.\n",
    "                sub = [word_list[i][0],word_list[i+1][0],word_list[i+2][0]]\n",
    "                subjects.append(' '.join(sub))\n",
    "                print('--------------------')\n",
    "            \n",
    "    except IndexError:\n",
    "        # Break the loop if IndexError occurs\n",
    "        # Fail safe\n",
    "        print(\"Out of Index\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word_POS-TAG_Person</th>\n",
       "      <th>nullColumn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humor_SBAR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>made_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mirror_SBAR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>persons_NP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>turned_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frights_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pieces_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>worked_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>much_ADVP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>eyes_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stayed_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>people_NP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mirror_SBAR</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>possessed_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>persons_NP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>heart_ADVP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>made_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>one_NP_CARDINAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>large_ADJP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>used_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>windowpanes_VP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word_POS-TAG_Person nullColumn\n",
       "0           humor_SBAR           \n",
       "1              made_VP           \n",
       "2          mirror_SBAR           \n",
       "3           persons_NP           \n",
       "4            turned_VP           \n",
       "5           frights_VP           \n",
       "6            pieces_VP           \n",
       "7            worked_VP           \n",
       "8            much_ADVP           \n",
       "9              eyes_VP           \n",
       "10           stayed_VP           \n",
       "11           people_NP           \n",
       "12         mirror_SBAR           \n",
       "13        possessed_VP           \n",
       "14          persons_NP           \n",
       "15          heart_ADVP           \n",
       "16             made_VP           \n",
       "17     one_NP_CARDINAL           \n",
       "18          large_ADJP           \n",
       "19             used_VP           \n",
       "20      windowpanes_VP           "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find PERSONs in the filtered sentence using spaCy NER and build a DataFrame Object based on the data\n",
    "# DataFrame structure -> Word | POS_TAG | Person\n",
    "\n",
    "#Convert the subjects array to a 2D numpy array\n",
    "subjects = np.array(subjects)\n",
    "subjects = np.reshape(subjects, (-1,1))\n",
    "\n",
    "refferingDataFrame = pd.DataFrame(columns=('Word_POS-TAG_Person','nullColumn'))\n",
    "\n",
    "for i in range(0,len(subjects)):\n",
    "    for j in range(0,len(subjects[i][0].split(\" \"))):\n",
    "        wordBag = subjects[i][0].split(\" \")\n",
    "        # Find POS_TAG \n",
    "        pos = ct.tag([wordBag[j]])\n",
    "        \n",
    "        # Find IF word is Person\n",
    "        person = [ent.label_ for ent in nlp(pos[0][0]).ents]\n",
    "        person = ' '.join(person)\n",
    "        if not person:\n",
    "            person = \"\"\n",
    "            \n",
    "        #Add a row to the DataFrame with the retrived data\n",
    "        refferingDataFrame.loc[len(refferingDataFrame)] = [(pos[0][0] +\"_\"+ pos[0][1].split('-')[1] +\"_\"+ person).rstrip('_'), \"\"]\n",
    "        \n",
    "refferingDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create the LSTM RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 25.0% Completed\n",
      "Training 50.0% Completed\n",
      "Training 75.0% Completed\n",
      "Training Complete!\n",
      "Total Training time : 24.31 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The RNN is created using PyTorch Framework with Cuda disabled. The RNN will clasify the Question according the the catogiry\n",
    "# To enable cuda add .cuda() method to torch.randn() method\n",
    "lstm = nn.LSTM(3, 3)\n",
    "inputs = [autograd.Variable(torch.randn(1, 3)) for _ in range(5)]\n",
    "hidden = (autograd.Variable(torch.randn(1, 1, 3)), autograd.Variable(torch.randn(1, 1, 3)))\n",
    "\n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    \n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (autograd.Variable(torch.randn(1, 1, 3)), autograd.Variable(torch.randn(1, 1, 3)))\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "#print(out)\n",
    "#print(hidden)\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return autograd.Variable(tensor)\n",
    "\n",
    "# Read training data from the csv\n",
    "# Training data format => [([\"Phrase\"], [\"Question\"])]\n",
    "unprocessed_data = pd.read_csv('Train_and_test_data/LSTM_train_set.csv',header=None)\n",
    "\n",
    "# Transform the data in to a processable format\n",
    "t_data_for_lstm = []\n",
    "training_data = []\n",
    "for phrase in unprocessed_data.itertuples():\n",
    "    t_data_for_lstm.append(list(zip([[phrase[1]]], [[phrase[2]]])))\n",
    "\n",
    "for i in range(0, len(t_data_for_lstm)):\n",
    "    training_data.append(t_data_for_lstm[i][0])\n",
    "    \n",
    "word_to_ix = {}\n",
    "tag_to_ix = {}\n",
    "\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "    for word1 in tags:\n",
    "        if word1 not in tag_to_ix:\n",
    "            tag_to_ix[word1] = len(tag_to_ix)\n",
    "                            \n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "# Create the model\n",
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden  = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)), autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space)\n",
    "        return tag_scores\n",
    "    \n",
    "# set the variables to Train the model\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "#Values Before Training\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "t0 = time.time()\n",
    "iterations = 300\n",
    "progress_after = iterations/4\n",
    "\n",
    "# Train the RNN for 300 iterations\n",
    "for epoch in range(0,iterations):\n",
    "    for sentence, tags in training_data:\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "        # Calculate the % of completion\n",
    "        if(progress_after == epoch):\n",
    "            print(\"Training {}% Completed\".format((progress_after / iterations) * 100))\n",
    "            progress_after = progress_after + (iterations / 4)\n",
    "            \n",
    "        tag_scores = model(sentence_in)\n",
    "        \n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print(\"Training Complete!\\nTotal Training time :\", round(time.time()-t0, 2), \"s\\n\")\n",
    "\n",
    "# #Values after training        \n",
    "# inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "# tag_scores = model(inputs)\n",
    "\n",
    "# print(\"Values After training\")\n",
    "# print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format the result generated by the LSTM by adding the relelevent Noun Phrases\n",
    "def generate_questions(model, ref_data_frame):\n",
    "    question = \"\"\n",
    "    sentence = \"\"\n",
    "    index = 0\n",
    "    # for all the entries in the ref_data_frame predict a question\n",
    "    for index, word_phrase in ref_data_frame.iterrows():\n",
    "        \n",
    "        # Predict the potentian sentence structure that can be used to generate the question.\n",
    "        try:\n",
    "            inputs = prepare_sequence([word_phrase[0]], word_to_ix)\n",
    "            tag_scores = model(inputs)\n",
    "        except KeyError:\n",
    "            # ignore\n",
    "            pass\n",
    "\n",
    "        # Take the maximum probalilty, and based on the probabilty find index of value of the dictonary\n",
    "        maxVal = max(tag_scores.data.numpy()[0])\n",
    "        index_loc = 0\n",
    "        probability_tag_scores = tag_scores.data.numpy().ravel()\n",
    "\n",
    "        for i in range(0, len(probability_tag_scores)):\n",
    "            if (probability_tag_scores.ravel()[i] == maxVal):\n",
    "                index_loc = i\n",
    "\n",
    "        # Travers the dictonary and identify the key value based on the probability predicted\n",
    "        for key, value in tag_to_ix.items():\n",
    "            if (value == index_loc):\n",
    "                # format the Key to generate a meaningfull question\n",
    "                # extract subject and object of the tested sentence\n",
    "                sentence = word_phrase[0].split('_')\n",
    "                # Check whether the question needs modification\n",
    "                if \"NP\" in sentence:\n",
    "                    question = key.replace(\"NP\", sentence[0])\n",
    "                    print(question)\n",
    "                elif \"VP\" in sentence:\n",
    "                    if \"NP\" in key and \"N1\" in key:\n",
    "                        # Find the complete sentence matching for the verb\n",
    "                        # Find the index in subjects which matches for verb\n",
    "                        index = [i for i,j in enumerate(subjects.ravel()) if sentence[0] in j]\n",
    "                        ref_subject = subjects.ravel()[index][0].split()\n",
    "                        # Replace for words NP and NP1\n",
    "                        question = key.replace(\"NP\", ref_subject[0]) \n",
    "                        question = question.replace(\"N1\",ref_subject[-1])\n",
    "                        print(question)\n",
    "                        \n",
    "                    else:\n",
    "                        # If \"VP\" but only one \"NP\"\n",
    "                        index = [i for i,j in enumerate(subjects.ravel()) if sentence[0] in j]\n",
    "                        ref_subject = subjects.ravel()[index][0].split()\n",
    "                        question = key.replace(\"NP\", ref_subject[0])\n",
    "                        print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What did humor make ?\n",
      "Who are persons ?\n",
      "why did persons turn ?\n",
      "Why did persons frighten ?\n",
      "What are the pieces refers to in the story ? \n",
      "What pieces worked ?\n",
      "What is meant by eyes ?\n",
      "What did stay regarding to eyes ?\n",
      "Who are people ?\n",
      "Why mirror possessed persons\n",
      "Who are persons ?\n",
      "What did humor make ?\n",
      "What did one make ?\n",
      "What was “used” in this passage ?\n",
      "What was “used” in this passage ?\n"
     ]
    }
   ],
   "source": [
    "generate_questions(model, refferingDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
